{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 변환\n",
    "## 목차\n",
    "- python-weka-wrapper\n",
    "- CSV 형식에서 ARFF 데이터 변환\n",
    "- 데이터 불러오기\n",
    "- Train data와 Test data 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [python-weka-wrapper](https://fracpete.github.io/python-weka-wrapper/index.html)\n",
    "- Python에서 `Weka`를 사용할 수 있습니다.\n",
    "- 이 라이브러리는 Weka 프로세스가 실행되는 Java 가상머신을 시작, 통신 및 종료하는 데 javabridge 라이브러리를 사용합니다.\n",
    "\n",
    "## `wrapper` 모듈 (작성한 코드)\n",
    "- python-weka-wrapper API를 좀 더 편히 쓰기 위해 만든 모듈\n",
    "\n",
    "```python\n",
    "def csv2arff(fname_csv, header)\n",
    "def load_data(dfile)\n",
    "def save_train_test_split(dfile, percentage, rng=None)\n",
    "def scatter_plots(dfile, outpath='./assets/scatter_plot/')\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV 형식에서 ARFF 데이터 변환\n",
    "- `Weka`의 API를 사용하기 위해 데이터의 형식을 ARFF로 변환합니다.\n",
    "- ARFF는 데이터는 CSV와 동일하고, 헤더에 `Attribute`(특징) 정보를 입력해야합니다.\n",
    "- `iris.arff`의 예입니다.\n",
    "\n",
    "```csv\n",
    "% Comment(주석)\n",
    "@RELATION iris\n",
    "\n",
    "@ATTRIBUTE sepallength\tNUMERIC\n",
    "@ATTRIBUTE sepalwidth \tNUMERIC\n",
    "@ATTRIBUTE petallength    NUMERIC\n",
    "@ATTRIBUTE petalwidth\t NUMERIC\n",
    "@ATTRIBUTE class \t     {Iris-setosa,Iris-versicolor,Iris-virginica}\n",
    "\n",
    "@DATA\n",
    "5.1,3.5,1.4,0.2,Iris-setosa\n",
    "4.9,3.0,1.4,0.2,Iris-setosa\n",
    "... (데이터) ...\n",
    "```\n",
    "\n",
    "- `wrapper.csv2arff`  \n",
    "   csv 파일을 arff로 변환하는 함수입니다. (헤더 정보가 필요합니다.)\n",
    "\n",
    "```python\n",
    "# wrapper.csv2arff\n",
    "def csv2arff(fname_csv, header):\n",
    "    \"\"\"arff header 정보로 csv로 부터 csv와 동일한 경로에 arff 파일을 생성한다.\n",
    "    e.g. /data/path/to/iris.csv로 부터 /data/path/to/iris.arff 파일 생성\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fname_csv : str, csv filename\n",
    "    header : str, arff 파일을 만들기 위한 헤더 정보[1].\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    .. [1] `WEKA, Attribute-Relation File Format (ARFF), \n",
    "           <https://www.cs.waikato.ac.nz/ml/weka/arff.html>`_\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrapper\n",
    "# ./datasets/housing.data로 부터 ./datasets/housing.arff 생성\n",
    "\n",
    "header = \"\"\"\n",
    "% 1. Title: Boston Housing Data\n",
    "% \n",
    "% 2. Sources:\n",
    "%    (a) Origin:  This dataset was taken from the StatLib library which is\n",
    "%                 maintained at Carnegie Mellon University.\n",
    "%    (b) Creator:  Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the \n",
    "%                  demand for clean air', J. Environ. Economics & Management,\n",
    "%                  vol.5, 81-102, 1978.\n",
    "%    (c) Date: July 7, 1993\n",
    "% \n",
    "% 3. Past Usage:\n",
    "%    -   Used in Belsley, Kuh & Welsch, 'Regression diagnostics ...', Wiley, \n",
    "%        1980.   N.B. Various transformations are used in the table on\n",
    "%        pages 244-261.\n",
    "%     -  Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning.\n",
    "%        In Proceedings on the Tenth International Conference of Machine \n",
    "%        Learning, 236-243, University of Massachusetts, Amherst. Morgan\n",
    "%        Kaufmann.\n",
    "% \n",
    "% 4. Relevant Information:\n",
    "% \n",
    "%    Concerns housing values in suburbs of Boston.\n",
    "% \n",
    "% 5. Number of Instances: 506\n",
    "% \n",
    "% 6. Number of Attributes: 13 continuous attributes (including \"class\"\n",
    "%                          attribute \"MEDV\"), 1 binary-valued attribute.\n",
    "% \n",
    "% 7. Attribute Information:\n",
    "% \n",
    "%     1. CRIM      per capita crime rate by town\n",
    "%     2. ZN        proportion of residential land zoned for lots over \n",
    "%                  25,000 sq.ft.\n",
    "%     3. INDUS     proportion of non-retail business acres per town\n",
    "%     4. CHAS      Charles River dummy variable (= 1 if tract bounds \n",
    "%                  river; 0 otherwise)\n",
    "%     5. NOX       nitric oxides concentration (parts per 10 million)\n",
    "%     6. RM        average number of rooms per dwelling\n",
    "%     7. AGE       proportion of owner-occupied units built prior to 1940\n",
    "%     8. DIS       weighted distances to five Boston employment centres\n",
    "%     9. RAD       index of accessibility to radial highways\n",
    "%     10. TAX      full-value property-tax rate per $10,000\n",
    "%     11. PTRATIO  pupil-teacher ratio by town\n",
    "%     12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks \n",
    "%                  by town\n",
    "%     13. LSTAT    % lower status of the population\n",
    "%     14. MEDV     Median value of owner-occupied homes in $1000's\n",
    "% \n",
    "% 8. Missing Attribute Values:  None.\n",
    "@RELATION \"Boston Housing\"\n",
    "\n",
    "@ATTRIBUTE CRIM  NUMERIC\n",
    "@ATTRIBUTE ZN    NUMERIC\n",
    "@ATTRIBUTE INDUS NUMERIC\n",
    "@ATTRIBUTE CHAS  {0,1}\n",
    "@ATTRIBUTE NOX NUMERIC\n",
    "@ATTRIBUTE RM NUMERIC\n",
    "@ATTRIBUTE AGE NUMERIC\n",
    "@ATTRIBUTE DIS NUMERIC\n",
    "@ATTRIBUTE RAD NUMERIC\n",
    "@ATTRIBUTE TAX NUMERIC\n",
    "@ATTRIBUTE PTRATIO NUMERIC\n",
    "@ATTRIBUTE B NUMERIC\n",
    "@ATTRIBUTE LSTAT NUMERIC\n",
    "@ATTRIBUTE MEDV NUMERIC\n",
    "\n",
    "@DATA\n",
    "\"\"\".strip()\n",
    "\n",
    "fname_csv = \"./datasets/housing.data\"\n",
    "wrapper.csv2arff(fname_csv, header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data와 Test data 분리\n",
    "- `wrapper.load_data`  \n",
    "  arff형식의 파일명을 입력받아 Weka API를 사용할 수 있는 data 클래스로 반환합니다.\n",
    "- `wrapper.save_train_test_split`  \n",
    "  arff형식의 파일명을 입력받아 데이터를 비율(`percentage`)을 입력받아 train과 test 데이터 파일 분리하여 파일을 생성합니다.\n",
    "  \n",
    "```python\n",
    "def load_data(dfile):\n",
    "    \"\"\"arff 형식의 데이터 파일경로를 입력받아 Weka API의 사용할 data 클래스를 반환한다.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfile: str, 데이터 파일경로, arff 형식의 데이터\n",
    "    \n",
    "    Note\n",
    "    ----------\n",
    "    예측 클래스를 마지막 Attribute(열, column)으로 설정한다.\n",
    "    `jvm`이 시작 상태여야 한다.\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    data: Weka API를 사용할 수 있는 data 클래스\n",
    "    \"\"\"\n",
    "    loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n",
    "    data = loader.load_file(dfile)\n",
    "    data.class_is_last()  # 예측 클래스를 마지막 Attribute로 설정.\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_train_test_split(dfile, percentage, rng=None):\n",
    "    \"\"\"dfile(arff 형식의 데이터 파일경로)를 입력받아, train과 test 데이터를 분리하여\n",
    "    dfile과 동일한 경로에 train.arff와 test.arff 파일을 생성한다.\n",
    "    e.g. /data/path/to/iris.arff로 부터 /data/path/to/iris_train.arff와\n",
    "         /data/path/to/iris_test.arff 파일 생성\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dfile: str, 데이터 파일경로, arff 형식의 데이터\n",
    "    \n",
    "    Note\n",
    "    ----------\n",
    "    `jvm`이 시작 상태여야 한다.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weka.core.jvm:Adding bundled jars\n",
      "DEBUG:weka.core.jvm:Classpath=['/opt/conda/envs/py36/lib/python3.6/site-packages/javabridge/jars/rhino-1.7R4.jar', '/opt/conda/envs/py36/lib/python3.6/site-packages/javabridge/jars/runnablequeue.jar', '/opt/conda/envs/py36/lib/python3.6/site-packages/javabridge/jars/cpython.jar', '/opt/conda/envs/py36/lib/python3.6/site-packages/weka/lib/weka.jar', '/opt/conda/envs/py36/lib/python3.6/site-packages/weka/lib/python-weka-wrapper.jar']\n",
      "DEBUG:weka.core.jvm:MaxHeapSize=default\n",
      "DEBUG:weka.core.jvm:Package support disabled\n"
     ]
    }
   ],
   "source": [
    "import weka.core.jvm as jvm\n",
    "import wrapper\n",
    "from weka.core.classes import Random\n",
    "# \"./dataset/housing.arff\"로 부터 ./dataset/housing_train.arff\n",
    "#                               ./dataset/housing_test.arff 생성\n",
    "\n",
    "# python-weka-wrapper를 사용하기 위한 jvm 실행\n",
    "# jvm이 다시 시작이 안되는 경우 커널을 재시작 해주세요\n",
    "jvm.start()\n",
    "\n",
    "# 실험 재현을 위한 rng(random number generator) 설정\n",
    "# arff 데이터를 입력받아 train 70%, test 나머지로 분리\n",
    "rng = Random(777)\n",
    "dfile = \"./datasets/housing.arff\"\n",
    "wrapper.save_train_test_split(dfile, 70, rng)\n",
    "\n",
    "jvm.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
